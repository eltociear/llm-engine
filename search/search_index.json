{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u26a1 Spellbook Serve \u26a1","text":"<p>The fastest, cheapest, and easiest way to deploy and scale your custom foundation models.</p>"},{"location":"#quick-install","title":"\ud83d\udcbb Quick Install","text":"Install using pipInstall using conda <pre><code>pip install spellbook-serve-client\n</code></pre> <pre><code>conda install spellbook-serve-client -c conda-forge\n</code></pre>"},{"location":"#about","title":"\ud83e\udd14 About","text":"<p>Foundation models are emerging as the building blocks of AI. However, deploying these models to the cloud still requires infrastructure expertise, and can be expensive.</p> <p>Spellbook Serve is a Python library, CLI, and Helm chart that provides everything you need to deploy your foundation models to the cloud using Kubernetes. Key features include:</p> <p>\ud83d\udc33 Deploying from any docker image: Turn any Docker image into an auto-scaling deployment with simple APIs.</p> <p>\ud83c\udf99\ufe0fLanguage-Model Specific Features: Spellbook Serve provides APIs for streaming responses and dynamically batching inputs for higher throughput and lower latency.</p> <p>\ud83e\udd17 Open-Source Integrations: Deploy any Huggingface model with a single command. Integrate seamlessly with Langchain chat applications.</p>"},{"location":"#features-coming-soon","title":"\ud83d\udd25 Features Coming Soon","text":"<p>\u2744 Fast Cold-Start Times: To prevent GPUs from idling, Spellbook Serve automatically scales your model to zero when it's not in use and scales up within seconds, even for large foundation models.</p> <p>\ud83d\udcb8 Cost-Optimized: Deploy AI models an order of magnitude cheaper than OpenAI APIs, including cold-start and warm-down times.</p>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"getting_started/","title":"\ud83d\ude80 Getting Started","text":"<p>To start using Spellbook Serve with public inference APIs, simply run the following:</p> Install using pipInstall using conda <pre><code>pip install spellbook-serve\n</code></pre> <pre><code>conda install spellbook-serve -c conda-forge\n</code></pre> <p>Navigate to https://spellbook.scale.com where you will get a Scale API key.</p> <p>With the API key, you can now send requests to Spellbook Serve public inference APIs using the CLI or Python client:</p> Using the CLIUsing the Python Client <pre><code>spellbook-serve generate flan-t5-xxl \\\n    --prompt \"Hello, my name is\"\n    --temperature 0.5\n    --max-tokens 20\n\n# Expected output:\n#\n# Hello, my name is Flan.\n</code></pre> <pre><code>from spellbook_serve_client import Client\nclient = Client()\nresponse = client.generate(\nmodel_name=\"flan-t5-xxl\",\nprompt=\"Hello, my name is\",\ntemperature=0.5,\nmax_tokens=20,\n)\nprint(response)\n</code></pre>"},{"location":"getting_started/#installation-on-kubernetes","title":"\ud83d\udcbb Installation on Kubernetes","text":"<p>To install Spellbook Serve on your infrastructure in Kubernetes, you can use the Helm chart:</p> <pre><code>helm repo add spellbook https://spellbook.github.io/helm-charts\nhelm repo update\nhelm install spellbook-serve spellbook/spellbook-serve\n</code></pre>"},{"location":"api/langchain/","title":"\ud83e\udd9c Langchain","text":"<p>Coming soon!</p>"},{"location":"api/python_client/","title":"Python Client API Reference","text":""},{"location":"api/python_client/#spellbook_serve_client.Completion","title":"Completion","text":"<p>         Bases: <code>APIEngine</code></p> <p>Completion API. This API is used to generate text completions.</p> Example <pre><code>from spellbook_serve_client import Completion\nresponse = Completion.create(\nmodel_name=\"llama-7b-text-generation-inference\",\nprompt=\"Hello, my name is\",\nmax_new_tokens=10,\ntemperature=0.2,\n)\nprint(response.outputs[0].text)\n</code></pre> Example <pre><code>from spellbook_serve_client import Completion\nresponse_stream = Completion.create(\nmodel_name=\"llama-7b-text-generation-inference\",\nprompt=\"Hello, my name is\",\nmax_new_tokens=10,\ntemperature=0.2,\nstream=True,\n)\nfor response in response_stream:\nprint(response.output.text)\n</code></pre> Example <pre><code>from spellbook_serve_client import Completion\nasync def main():\nresponse_stream = await Completion.acreate(\nmodel_name=\"llama-7b-text-generation-inference\",\nprompt=\"Hello, my name is\",\nmax_new_tokens=10,\ntemperature=0.2,\nstream=True,\n)\nasync for response in response_stream:\nprint(response.output.text)\n</code></pre>"},{"location":"api/python_client/#spellbook_serve_client.completion.Completion.acreate","title":"acreate  <code>async</code> <code>classmethod</code>","text":"<pre><code>acreate(\nmodel_name: str,\nprompt: str,\nmax_new_tokens: int = 20,\ntemperature: float = 0.2,\ntimeout: int = 10,\nstream: bool = False,\n) -&gt; Union[\nCompletionSyncV1Response,\nAsyncIterable[CompletionStreamV1Response],\n]\n</code></pre> <p>Create a completion task.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Model name to use for inference</p> required <code>prompt</code> <code>str</code> <p>Input text</p> required <code>max_new_tokens</code> <code>int</code> <p>Maximum number of generated tokens</p> <code>20</code> <code>temperature</code> <code>float</code> <p>The value used to module the logits distribution.</p> <code>0.2</code> <code>timeout</code> <code>int</code> <p>Timeout in seconds</p> <code>10</code> <code>stream</code> <code>bool</code> <p>Whether to stream the response. If true, the return type is an <code>Iterator[CompletionStreamV1Response]</code>.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>response</code> <code>CompletionStreamV1Response</code> <p>generated response or iterator of response chunks</p>"},{"location":"api/python_client/#spellbook_serve_client.completion.Completion.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(\nmodel_name: str,\nprompt: str,\nmax_new_tokens: int = 20,\ntemperature: float = 0.2,\ntimeout: int = 10,\nstream: bool = False,\n) -&gt; Union[\nCompletionSyncV1Response,\nIterator[CompletionStreamV1Response],\n]\n</code></pre> <p>Create a completion task.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Model name to use for inference</p> required <code>prompt</code> <code>str</code> <p>Input text</p> required <code>max_new_tokens</code> <code>int</code> <p>Maximum number of generated tokens</p> <code>20</code> <code>temperature</code> <code>float</code> <p>The value used to module the logits distribution.</p> <code>0.2</code> <code>timeout</code> <code>int</code> <p>Timeout in seconds</p> <code>10</code> <code>stream</code> <code>bool</code> <p>Whether to stream the response. If true, the return type is an <code>Iterator</code>.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>response</code> <code>CompletionStreamV1Response</code> <p>generated response or iterator of response chunks</p>"},{"location":"api/python_client/#spellbook_serve_client.FineTune","title":"FineTune","text":"<p>         Bases: <code>APIEngine</code></p> <p>FineTune API. This API is used to fine-tune models.</p>"},{"location":"api/python_client/#spellbook_serve_client.fine_tuning.FineTune.cancel","title":"cancel  <code>classmethod</code>","text":"<pre><code>cancel(fine_tune_id: str) -&gt; CancelFineTuneJobResponse\n</code></pre> <p>Cancel a fine-tuning job</p> <p>Parameters:</p> Name Type Description Default <code>fine_tune_id</code> <code>`str`</code> <p>ID of the fine-tuning job</p> required <p>Returns:</p> Name Type Description <code>CancelFineTuneJobResponse</code> <code>CancelFineTuneJobResponse</code> <p>whether the cancellation was successful</p>"},{"location":"api/python_client/#spellbook_serve_client.fine_tuning.FineTune.create","title":"create  <code>classmethod</code>","text":"<pre><code>create(\ntraining_file: str,\nvalidation_file: str,\nmodel_name: str,\nbase_model: str,\nfine_tuning_method: str,\nhyperparameters: Dict[str, str],\n) -&gt; CreateFineTuneJobResponse\n</code></pre> <p>Create a fine-tuning job</p> <p>Parameters:</p> Name Type Description Default <code>training_file</code> <code>`str`</code> <p>Path to file of training dataset</p> required <code>validation_file</code> <code>`str`</code> <p>Path to file of validation dataset</p> required <code>model_name</code> <code>`str`</code> <p>Name of the fine-tuned model</p> required <code>base_model</code> <code>`str`</code> <p>Base model to train from</p> required <code>fine_tuning_method</code> <code>`str`</code> <p>Fine-tuning method</p> required <code>hyperparameters</code> <code>`str`</code> <p>Hyperparameters</p> required <p>Returns:</p> Name Type Description <code>CreateFineTuneJobResponse</code> <code>CreateFineTuneJobResponse</code> <p>ID of the created fine-tuning job</p>"},{"location":"api/python_client/#spellbook_serve_client.fine_tuning.FineTune.list","title":"list  <code>classmethod</code>","text":"<pre><code>list() -&gt; ListFineTuneJobResponse\n</code></pre> <p>List fine-tuning jobs</p> <p>Returns:</p> Name Type Description <code>ListFineTuneJobResponse</code> <code>ListFineTuneJobResponse</code> <p>list of all fine-tuning jobs and their statuses</p>"},{"location":"api/python_client/#spellbook_serve_client.fine_tuning.FineTune.retrieve","title":"retrieve  <code>classmethod</code>","text":"<pre><code>retrieve(fine_tune_id: str) -&gt; GetFineTuneJobResponse\n</code></pre> <p>Get status of a fine-tuning job</p> <p>Parameters:</p> Name Type Description Default <code>fine_tune_id</code> <code>`str`</code> <p>ID of the fine-tuning job</p> required <p>Returns:</p> Name Type Description <code>GetFineTuneJobResponse</code> <code>GetFineTuneJobResponse</code> <p>ID and status of the requested job</p>"},{"location":"api/python_client/#spellbook_serve_client.CompletionSyncV1Response","title":"CompletionSyncV1Response","text":"<p>         Bases: <code>BaseModel</code></p> <p>Response object for a synchronous prompt completion task.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionSyncV1Response.outputs","title":"outputs  <code>class-attribute</code>","text":"<pre><code>outputs: List[CompletionOutput]\n</code></pre> <p>List of completion outputs.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionSyncV1Response.status","title":"status  <code>class-attribute</code>","text":"<pre><code>status: TaskStatus\n</code></pre> <p>Task status.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionSyncV1Response.traceback","title":"traceback  <code>class-attribute</code>","text":"<pre><code>traceback: Optional[str] = None\n</code></pre> <p>Traceback if the task failed.</p>"},{"location":"api/python_client/#spellbook_serve_client.CompletionStreamV1Response","title":"CompletionStreamV1Response","text":"<p>         Bases: <code>BaseModel</code></p> <p>Response object for a stream prompt completion task.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionStreamV1Response.output","title":"output  <code>class-attribute</code>","text":"<pre><code>output: Optional[CompletionStreamOutput] = None\n</code></pre> <p>Completion output.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionStreamV1Response.status","title":"status  <code>class-attribute</code>","text":"<pre><code>status: TaskStatus\n</code></pre> <p>Task status.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionStreamV1Response.traceback","title":"traceback  <code>class-attribute</code>","text":"<pre><code>traceback: Optional[str] = None\n</code></pre> <p>Traceback if the task failed.</p>"},{"location":"api/python_client/#spellbook_serve_client.CompletionOutput","title":"CompletionOutput","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionOutput.num_completion_tokens","title":"num_completion_tokens  <code>class-attribute</code>","text":"<pre><code>num_completion_tokens: int\n</code></pre> <p>Number of tokens in the completion.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionOutput.num_prompt_tokens","title":"num_prompt_tokens  <code>class-attribute</code>","text":"<pre><code>num_prompt_tokens: Optional[int]\n</code></pre> <p>Number of tokens in the prompt.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionOutput.text","title":"text  <code>class-attribute</code>","text":"<pre><code>text: str\n</code></pre> <p>Text</p>"},{"location":"api/python_client/#spellbook_serve_client.CompletionStreamOutput","title":"CompletionStreamOutput","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionStreamOutput.finished","title":"finished  <code>class-attribute</code>","text":"<pre><code>finished: bool\n</code></pre> <p>Whether the completion is finished.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionStreamOutput.num_completion_tokens","title":"num_completion_tokens  <code>class-attribute</code>","text":"<pre><code>num_completion_tokens: Optional[int] = None\n</code></pre> <p>Number of tokens in the completion.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionStreamOutput.num_prompt_tokens","title":"num_prompt_tokens  <code>class-attribute</code>","text":"<pre><code>num_prompt_tokens: Optional[int] = None\n</code></pre> <p>Number of tokens in the prompt.</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CompletionStreamOutput.text","title":"text  <code>class-attribute</code>","text":"<pre><code>text: str\n</code></pre> <p>Text</p>"},{"location":"api/python_client/#spellbook_serve_client.TaskStatus","title":"TaskStatus","text":"<p>         Bases: <code>str</code>, <code>Enum</code></p>"},{"location":"api/python_client/#spellbook_serve_client.CreateFineTuneJobRequest","title":"CreateFineTuneJobRequest","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CreateFineTuneJobRequest.base_model","title":"base_model  <code>class-attribute</code>","text":"<pre><code>base_model: str\n</code></pre> <p>Base model to train from</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CreateFineTuneJobRequest.fine_tuning_method","title":"fine_tuning_method  <code>class-attribute</code>","text":"<pre><code>fine_tuning_method: str\n</code></pre> <p>Fine-tuning method</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CreateFineTuneJobRequest.hyperparameters","title":"hyperparameters  <code>class-attribute</code>","text":"<pre><code>hyperparameters: Dict[str, str]\n</code></pre> <p>Hyperparameters</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CreateFineTuneJobRequest.model_name","title":"model_name  <code>class-attribute</code>","text":"<pre><code>model_name: str\n</code></pre> <p>Name of the fine-tuned model</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CreateFineTuneJobRequest.training_file","title":"training_file  <code>class-attribute</code>","text":"<pre><code>training_file: str\n</code></pre> <p>Path to file of training dataset</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CreateFineTuneJobRequest.validation_file","title":"validation_file  <code>class-attribute</code>","text":"<pre><code>validation_file: str\n</code></pre> <p>Path to file of validation dataset</p>"},{"location":"api/python_client/#spellbook_serve_client.CreateFineTuneJobResponse","title":"CreateFineTuneJobResponse","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CreateFineTuneJobResponse.fine_tune_id","title":"fine_tune_id  <code>class-attribute</code>","text":"<pre><code>fine_tune_id: str\n</code></pre> <p>ID of the created fine-tuning job</p>"},{"location":"api/python_client/#spellbook_serve_client.GetFineTuneJobResponse","title":"GetFineTuneJobResponse","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.GetFineTuneJobResponse.fine_tune_id","title":"fine_tune_id  <code>class-attribute</code>","text":"<pre><code>fine_tune_id: str\n</code></pre> <p>ID of the requested job</p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.GetFineTuneJobResponse.status","title":"status  <code>class-attribute</code>","text":"<pre><code>status: BatchJobStatus\n</code></pre> <p>Status of the requested job</p>"},{"location":"api/python_client/#spellbook_serve_client.ListFineTuneJobResponse","title":"ListFineTuneJobResponse","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.ListFineTuneJobResponse.jobs","title":"jobs  <code>class-attribute</code>","text":"<pre><code>jobs: List[GetFineTuneJobResponse]\n</code></pre> <p>List of fine-tuning jobs and their statuses</p>"},{"location":"api/python_client/#spellbook_serve_client.CancelFineTuneJobResponse","title":"CancelFineTuneJobResponse","text":"<p>         Bases: <code>BaseModel</code></p>"},{"location":"api/python_client/#spellbook_serve_client.data_types.CancelFineTuneJobResponse.success","title":"success  <code>class-attribute</code>","text":"<pre><code>success: bool\n</code></pre> <p>Whether cancellation was successful</p>"}]}